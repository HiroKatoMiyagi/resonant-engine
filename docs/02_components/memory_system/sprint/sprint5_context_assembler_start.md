# Sprint 5: Context Assembler â€” ä½œæ¥­é–‹å§‹æŒ‡ç¤ºæ›¸

**Sprint**: Sprint 5 - Context Assembler
**æœŸé–“**: 5æ—¥é–“ï¼ˆå®Ÿè£…3æ—¥ + ãƒ†ã‚¹ãƒˆãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼2æ—¥ï¼‰
**æ‹…å½“**: Tsumu (å®Ÿè£…å…·ç¾å±¤)
**ç›£ç£**: Kana (å¤–ç•Œç¿»è¨³å±¤) / Yuno (æ€æƒ³ä¸­æ¢å±¤)

---

## ğŸ¯ Sprintç›®æ¨™

**Claude APIã«éå»ã®æ–‡è„ˆã‚’æ¸¡ã™ã€Œè¨˜æ†¶çµ±åˆå±¤ã€ã‚’å®Ÿè£…ã—ã€çœŸã®ä¼šè©±è¨˜æ†¶æ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹**

### Before / After

#### Before (ç¾çŠ¶)
```python
# KanaAIBridge
messages = [
    {"role": "system", "content": "You are Kana..."},
    {"role": "user", "content": "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"}  # éå»ã®è¨˜æ†¶ãªã—ï¼
]
```

#### After (Sprint 5å®Œäº†å¾Œ)
```python
# Context Assemblerçµ±åˆå¾Œ
messages = [
    {"role": "system", "content": "You are Kana...\n## ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„\n..."},
    {"role": "assistant", "content": "## é–¢é€£ã™ã‚‹éå»ã®è¨˜æ†¶\n1. ...\n2. ..."},
    {"role": "user", "content": "5åˆ†å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"},
    {"role": "assistant", "content": "5åˆ†å‰ã®å¿œç­”"},
    {"role": "user", "content": "æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"}  # éå»ã®æ–‡è„ˆã‚’å«ã‚€ï¼
]
```

---

## ğŸ“‹ å‰ææ¡ä»¶

### å¿…é ˆã®å®Œäº†Sprint
- [x] Sprint 1: Memory Management (Session/Intentç®¡ç†)
- [x] Sprint 2: Semantic Bridge (è¨˜æ†¶æŠ½å‡º)
- [x] Sprint 3: Memory Store (pgvector)
- [x] Sprint 4: Retrieval Orchestrator (è¨˜æ†¶æƒ³èµ·)

### ç’°å¢ƒç¢ºèª

```bash
# 1. PostgreSQLãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹
psql -U postgres -d resonant -c "SELECT 1;"

# 2. memoriesãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹
psql -U postgres -d resonant -c "\d memories"

# 3. messagesãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹
psql -U postgres -d resonant -c "\d messages"

# 4. Pythonç’°å¢ƒ
python --version  # Python 3.11+
pip list | grep anthropic
pip list | grep pydantic
```

### ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‹•ä½œç¢ºèª

```python
# retrieval/orchestrator.py ãŒå‹•ä½œã™ã‚‹ã‹
from retrieval.orchestrator import create_orchestrator
print("Retrieval Orchestrator OK")

# backend/app/repositories/message_repo.py ãŒå‹•ä½œã™ã‚‹ã‹
from backend.app.repositories.message_repo import MessageRepository
print("Message Repository OK")

# bridge/providers/ai/kana_ai_bridge.py ãŒå‹•ä½œã™ã‚‹ã‹
from bridge.providers.ai.kana_ai_bridge import KanaAIBridge
print("KanaAIBridge OK")
```

---

## ğŸ“¦ æˆæœç‰©ãƒªã‚¹ãƒˆ

### 1. å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ | å¿…é ˆ |
|---------|------|------|
| `context_assembler/__init__.py` | ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ– | âœ… |
| `context_assembler/models.py` | ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆPydanticï¼‰ | âœ… |
| `context_assembler/service.py` | Context Assemblerãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ | âœ… |
| `context_assembler/token_estimator.py` | ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®š | âœ… |
| `context_assembler/config.py` | è¨­å®šç®¡ç† | âœ… |
| `bridge/providers/ai/kana_ai_bridge.py` | KanaAIBridgeæ‹¡å¼µï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£ï¼‰ | âœ… |

### 2. ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ | å¿…é ˆ |
|---------|------|------|
| `tests/context_assembler/test_service.py` | ã‚µãƒ¼ãƒ“ã‚¹å˜ä½“ãƒ†ã‚¹ãƒˆ | âœ… |
| `tests/context_assembler/test_token_estimator.py` | ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šãƒ†ã‚¹ãƒˆ | âœ… |
| `tests/context_assembler/test_integration.py` | çµ±åˆãƒ†ã‚¹ãƒˆ | âœ… |
| `tests/context_assembler/test_e2e.py` | E2Eãƒ†ã‚¹ãƒˆ | âœ… |

### 3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ | å¿…é ˆ |
|---------|------|------|
| `context_assembler/README.md` | ä½¿ç”¨æ–¹æ³•ãƒ»APIä»•æ§˜ | âœ… |
| `docs/.../sprint5_acceptance_test_spec.md` | å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆä»•æ§˜æ›¸ | âœ… |

---

## ğŸ› ï¸ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—

### Day 1: ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ã¨Token Estimator

#### Step 1.1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ

```bash
cd /home/user/resonant-engine
mkdir -p context_assembler
mkdir -p tests/context_assembler
touch context_assembler/__init__.py
touch tests/context_assembler/__init__.py
```

#### Step 1.2: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®Ÿè£…

`context_assembler/models.py`:

```python
"""Context Assembler - Data Models"""

from enum import Enum
from typing import Dict, List, Optional
from uuid import UUID

from pydantic import BaseModel, Field


class MemoryLayer(str, Enum):
    """ãƒ¡ãƒ¢ãƒªéšå±¤ã®ç¨®é¡"""
    SYSTEM = "system"
    WORKING = "working"
    SEMANTIC = "semantic"
    SESSION_SUMMARY = "session_summary"
    USER_MESSAGE = "user_message"


class ContextConfig(BaseModel):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š"""
    system_prompt: str = "You are Kana, the external translator for Resonant Engine."
    working_memory_limit: int = Field(default=10, ge=1, le=50)
    semantic_memory_limit: int = Field(default=5, ge=1, le=20)
    max_tokens: int = Field(default=100000, ge=1000)
    token_safety_margin: float = Field(default=0.8, ge=0.5, le=0.95)


class AssemblyOptions(BaseModel):
    """çµ„ã¿ç«‹ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³"""
    working_memory_limit: Optional[int] = None
    semantic_memory_limit: Optional[int] = None
    include_semantic_memory: bool = True
    include_session_summary: bool = True


class ContextMetadata(BaseModel):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
    working_memory_count: int = Field(..., ge=0)
    semantic_memory_count: int = Field(..., ge=0)
    has_session_summary: bool
    total_tokens: int = Field(..., ge=0)
    token_limit: int = Field(..., ge=0)
    compression_applied: bool
    assembly_latency_ms: float = Field(..., ge=0)


class AssembledContext(BaseModel):
    """çµ„ã¿ç«‹ã¦æ¸ˆã¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    messages: List[Dict[str, str]]
    metadata: ContextMetadata

    class Config:
        from_attributes = True
```

**ãƒ†ã‚¹ãƒˆä½œæˆ**: `tests/context_assembler/test_models.py`

```python
import pytest
from context_assembler.models import ContextConfig, AssemblyOptions, ContextMetadata


def test_context_config_defaults():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ãƒ†ã‚¹ãƒˆ"""
    config = ContextConfig()
    assert config.working_memory_limit == 10
    assert config.semantic_memory_limit == 5
    assert config.max_tokens == 100000
    assert config.token_safety_margin == 0.8


def test_context_config_validation():
    """è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼"""
    # ä¸æ­£ãªå€¤
    with pytest.raises(ValueError):
        ContextConfig(working_memory_limit=0)  # ge=1

    with pytest.raises(ValueError):
        ContextConfig(token_safety_margin=1.1)  # le=0.95


def test_assembly_options():
    """çµ„ã¿ç«‹ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    options = AssemblyOptions(
        include_semantic_memory=False
    )
    assert options.include_semantic_memory is False
    assert options.include_session_summary is True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
```

**å®Ÿè¡Œ**: `pytest tests/context_assembler/test_models.py -v`

#### Step 1.3: Token Estimatorå®Ÿè£…

`context_assembler/token_estimator.py`:

```python
"""Token Estimator - ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®š"""

from typing import Dict, List


class TokenEstimator:
    """
    ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šã‚¯ãƒ©ã‚¹

    ç°¡æ˜“æ¨å®šãƒ­ã‚¸ãƒƒã‚¯:
    - æ—¥æœ¬èª1æ–‡å­— â‰ˆ 2ãƒˆãƒ¼ã‚¯ãƒ³
    - è‹±èª1æ–‡å­— â‰ˆ 0.5ãƒˆãƒ¼ã‚¯ãƒ³
    - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: 10ãƒˆãƒ¼ã‚¯ãƒ³/ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """

    def estimate(self, messages: List[Dict[str, str]]) -> int:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š

        Args:
            messages: Claude APIå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ

        Returns:
            æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        total = 0

        for msg in messages:
            content = msg.get("content", "")

            # æ—¥æœ¬èªæ–‡å­—æ•°ï¼ˆUnicodeã®CJKç¯„å›²ï¼‰
            japanese_chars = sum(
                1 for c in content
                if 0x3000 <= ord(c) <= 0x9FFF or 0xFF00 <= ord(c) <= 0xFFEF
            )

            # ãã®ä»–ã®æ–‡å­—æ•°
            other_chars = len(content) - japanese_chars

            # æ¨å®š
            total += japanese_chars * 2
            total += other_chars * 0.5

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
            total += 10

        return int(total)

    def estimate_string(self, text: str) -> int:
        """
        å˜ä¸€æ–‡å­—åˆ—ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š

        Args:
            text: æ¨å®šå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        japanese_chars = sum(
            1 for c in text
            if 0x3000 <= ord(c) <= 0x9FFF or 0xFF00 <= ord(c) <= 0xFFEF
        )
        other_chars = len(text) - japanese_chars

        return int(japanese_chars * 2 + other_chars * 0.5)
```

**ãƒ†ã‚¹ãƒˆä½œæˆ**: `tests/context_assembler/test_token_estimator.py`

```python
from context_assembler.token_estimator import TokenEstimator


def test_estimate_japanese_text():
    """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š"""
    estimator = TokenEstimator()

    messages = [
        {"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"}  # 5æ–‡å­—
    ]

    tokens = estimator.estimate(messages)
    # 5æ–‡å­— * 2 + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰10 = 20
    assert 15 <= tokens <= 25


def test_estimate_english_text():
    """è‹±èªãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š"""
    estimator = TokenEstimator()

    messages = [
        {"role": "user", "content": "Hello World"}  # 11æ–‡å­—
    ]

    tokens = estimator.estimate(messages)
    # 11æ–‡å­— * 0.5 + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰10 = 15.5
    assert 10 <= tokens <= 20


def test_estimate_mixed_text():
    """æ—¥è‹±æ··åœ¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š"""
    estimator = TokenEstimator()

    messages = [
        {"role": "user", "content": "Resonant Engineã¯å‘¼å¸ã®ãƒªã‚ºãƒ ã§ã™"}
    ]

    tokens = estimator.estimate(messages)
    assert tokens > 20  # ãã‚Œãªã‚Šã®é‡


def test_estimate_multiple_messages():
    """è¤‡æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š"""
    estimator = TokenEstimator()

    messages = [
        {"role": "system", "content": "You are Kana"},
        {"role": "user", "content": "Hello"},
        {"role": "assistant", "content": "Hi"}
    ]

    tokens = estimator.estimate(messages)
    assert tokens > 30  # å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰


def test_estimate_string():
    """æ–‡å­—åˆ—ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š"""
    estimator = TokenEstimator()

    tokens = estimator.estimate_string("ã“ã‚“ã«ã¡ã¯")
    assert 8 <= tokens <= 12  # 5æ–‡å­— * 2 = 10
```

**å®Ÿè¡Œ**: `pytest tests/context_assembler/test_token_estimator.py -v`

---

### Day 2: Context Assembler Serviceå®Ÿè£…

#### Step 2.1: Configå®Ÿè£…

`context_assembler/config.py`:

```python
"""Context Assembler - Configuration"""

from context_assembler.models import ContextConfig


def get_default_config() -> ContextConfig:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å–å¾—"""
    return ContextConfig(
        system_prompt=(
            "You are Kana, the external translator for Resonant Engine.\n"
            "You help users understand and interact with the system by "
            "translating their intentions into structured actions."
        ),
        working_memory_limit=10,
        semantic_memory_limit=5,
        max_tokens=100000,  # Claude Sonnet 4.5: 200k (å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³è€ƒæ…®)
        token_safety_margin=0.8
    )
```

#### Step 2.2: Context Assembler Serviceå®Ÿè£…

`context_assembler/service.py`:

```python
"""Context Assembler Service - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ„ã¿ç«‹ã¦ã‚µãƒ¼ãƒ“ã‚¹"""

import asyncio
import time
from typing import Any, Dict, List, Optional, Tuple
from uuid import UUID

from memory_store.models import MemoryResult
from backend.app.models.message import MessageResponse
from backend.app.repositories.message_repo import MessageRepository
from bridge.memory.repositories import SessionRepository
from retrieval.orchestrator import RetrievalOrchestrator, RetrievalOptions

from .models import (
    AssembledContext,
    AssemblyOptions,
    ContextConfig,
    ContextMetadata,
)
from .token_estimator import TokenEstimator


class ContextAssemblerService:
    """
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ„ã¿ç«‹ã¦ã‚µãƒ¼ãƒ“ã‚¹

    Retrieval Orchestratorã‹ã‚‰ã®è¨˜æ†¶ã¨ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’çµ±åˆã—ã€
    Claude APIã«æ¸¡ã™æœ€é©ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        retrieval_orchestrator: RetrievalOrchestrator,
        message_repository: MessageRepository,
        session_repository: SessionRepository,
        config: ContextConfig,
    ):
        self.retrieval = retrieval_orchestrator
        self.message_repo = message_repository
        self.session_repo = session_repository
        self.config = config
        self.token_estimator = TokenEstimator()

    async def assemble_context(
        self,
        user_message: str,
        user_id: str,
        session_id: Optional[UUID] = None,
        options: Optional[AssemblyOptions] = None,
    ) -> AssembledContext:
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿ç«‹ã¦ã‚‹

        Args:
            user_message: ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            options: çµ„ã¿ç«‹ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³

        Returns:
            AssembledContext: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        start_time = time.time()
        options = options or AssemblyOptions()

        # 1. ãƒ¡ãƒ¢ãƒªéšå±¤ã‚’å–å¾—
        memory_layers = await self._fetch_memory_layers(
            user_message=user_message,
            user_id=user_id,
            session_id=session_id,
            options=options,
        )

        # 2. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
        messages = self._build_messages(memory_layers, user_message)

        # 3. ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
        total_tokens = self.token_estimator.estimate(messages)

        # 4. ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ãƒã‚§ãƒƒã‚¯ã¨åœ§ç¸®
        compression_applied = False
        if total_tokens > self._get_token_limit():
            messages, total_tokens = self._compress_context(
                messages, memory_layers, user_message
            )
            compression_applied = True

        # 5. æ¤œè¨¼
        self._validate_context(messages, total_tokens)

        assembly_time = (time.time() - start_time) * 1000

        # 6. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        metadata = ContextMetadata(
            working_memory_count=len(memory_layers.get("working", [])),
            semantic_memory_count=len(memory_layers.get("semantic", [])),
            has_session_summary=memory_layers.get("session_summary") is not None,
            total_tokens=total_tokens,
            token_limit=self._get_token_limit(),
            compression_applied=compression_applied,
            assembly_latency_ms=assembly_time,
        )

        return AssembledContext(messages=messages, metadata=metadata)

    async def _fetch_memory_layers(
        self,
        user_message: str,
        user_id: str,
        session_id: Optional[UUID],
        options: AssemblyOptions,
    ) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªéšå±¤ã‚’ä¸¦è¡Œå–å¾—"""
        tasks = []

        # Working Memoryï¼ˆç›´è¿‘ã®ä¼šè©±ï¼‰
        tasks.append(
            self._fetch_working_memory(
                user_id=user_id,
                limit=options.working_memory_limit
                or self.config.working_memory_limit,
            )
        )

        # Semantic Memoryï¼ˆé–¢é€£è¨˜æ†¶ï¼‰
        if options.include_semantic_memory:
            tasks.append(
                self._fetch_semantic_memory(
                    query=user_message,
                    limit=options.semantic_memory_limit
                    or self.config.semantic_memory_limit,
                )
            )
        else:
            tasks.append(asyncio.sleep(0, result=[]))

        # Session Summary
        if session_id and options.include_session_summary:
            tasks.append(self._fetch_session_summary(session_id))
        else:
            tasks.append(asyncio.sleep(0, result=None))

        # ä¸¦è¡Œå®Ÿè¡Œ
        working, semantic, summary = await asyncio.gather(*tasks)

        return {
            "working": working,
            "semantic": semantic,
            "session_summary": summary,
        }

    async def _fetch_working_memory(
        self, user_id: str, limit: int
    ) -> List[MessageResponse]:
        """Working Memory: ç›´è¿‘Nä»¶ã®ä¼šè©±"""
        messages, _ = await self.message_repo.list(user_id=user_id, limit=limit)
        # æ™‚ç³»åˆ—é †ï¼ˆå¤ã„â†’æ–°ã—ã„ï¼‰ã«ä¸¦ã³æ›¿ãˆ
        return list(reversed(messages))

    async def _fetch_semantic_memory(
        self, query: str, limit: int
    ) -> List[MemoryResult]:
        """Semantic Memory: é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
        response = await self.retrieval.retrieve(
            query=query, options=RetrievalOptions(limit=limit, log_metrics=False)
        )
        return response.results

    async def _fetch_session_summary(self, session_id: UUID) -> Optional[str]:
        """Session Summary: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¦ç´„ã‚’å–å¾—"""
        session = await self.session_repo.get_by_id(session_id)
        if session and session.metadata:
            return session.metadata.get("summary")
        return None

    def _build_messages(
        self, memory_layers: Dict[str, Any], user_message: str
    ) -> List[Dict[str, str]]:
        """Claude APIã«æ¸¡ã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        messages = []

        # 1. System Prompt
        system_content = self.config.system_prompt
        if memory_layers.get("session_summary"):
            system_content += (
                f"\n\n## ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„\n{memory_layers['session_summary']}"
            )

        messages.append({"role": "system", "content": system_content})

        # 2. Semantic Memory
        semantic_memories = memory_layers.get("semantic", [])
        if semantic_memories:
            memory_text = "## é–¢é€£ã™ã‚‹éå»ã®è¨˜æ†¶\n\n"
            for i, mem in enumerate(semantic_memories[:3], 1):
                memory_text += (
                    f"{i}. {mem.content} (é–¢é€£åº¦: {mem.similarity:.2f})\n"
                )

            messages.append({"role": "assistant", "content": memory_text})

        # 3. Working Memory
        working_messages = memory_layers.get("working", [])
        for msg in working_messages[-5:]:  # ç›´è¿‘5ä»¶
            role = self._map_message_type_to_role(msg.message_type)
            if role:  # systemã¯é™¤å¤–
                messages.append({"role": role, "content": msg.content})

        # 4. Current User Message
        messages.append({"role": "user", "content": user_message})

        return messages

    def _map_message_type_to_role(self, message_type: str) -> Optional[str]:
        """MessageTypeã‚’Claude API roleã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
        mapping = {
            "user": "user",
            "kana": "assistant",
            "yuno": "assistant",
            "system": None,  # systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™¤å¤–
        }
        return mapping.get(message_type.lower())

    def _compress_context(
        self,
        messages: List[Dict[str, str]],
        memory_layers: Dict[str, Any],
        user_message: str,
    ) -> Tuple[List[Dict[str, str]], int]:
        """ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã‚’è¶…ãˆãŸå ´åˆã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åœ§ç¸®"""
        compressed_layers = memory_layers.copy()

        # Phase 1: Session Summaryå‰Šé™¤
        if compressed_layers.get("session_summary"):
            compressed_layers["session_summary"] = None
            messages = self._build_messages(compressed_layers, user_message)
            tokens = self.token_estimator.estimate(messages)
            if tokens <= self._get_token_limit():
                return messages, tokens

        # Phase 2: Semantic Memoryå‰Šæ¸›
        semantic = compressed_layers.get("semantic", [])
        while len(semantic) > 1:
            semantic = semantic[:-1]  # æœ€å¾Œï¼ˆé¡ä¼¼åº¦ãŒä½ã„ï¼‰ã‹ã‚‰å‰Šé™¤
            compressed_layers["semantic"] = semantic
            messages = self._build_messages(compressed_layers, user_message)
            tokens = self.token_estimator.estimate(messages)
            if tokens <= self._get_token_limit():
                return messages, tokens

        # Phase 3: Working Memoryå‰Šæ¸›
        working = compressed_layers.get("working", [])
        while len(working) > 2:  # æœ€ä½2ä»¶ã¯æ®‹ã™
            working = working[1:]  # æœ€åˆï¼ˆå¤ã„ï¼‰ã‹ã‚‰å‰Šé™¤
            compressed_layers["working"] = working
            messages = self._build_messages(compressed_layers, user_message)
            tokens = self.token_estimator.estimate(messages)
            if tokens <= self._get_token_limit():
                return messages, tokens

        # ãã‚Œã§ã‚‚è¶…éã™ã‚‹å ´åˆã¯ç¾çŠ¶ã‚’è¿”ã™
        return messages, tokens

    def _get_token_limit(self) -> int:
        """ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã‚’è¨ˆç®—ï¼ˆå®‰å…¨ãƒãƒ¼ã‚¸ãƒ³è€ƒæ…®ï¼‰"""
        return int(self.config.max_tokens * self.config.token_safety_margin)

    def _validate_context(
        self, messages: List[Dict[str, str]], total_tokens: int
    ) -> None:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        # 1. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ãªã„ã‹
        if not messages:
            raise ValueError("Messages cannot be empty")

        # 2. æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒsystemã‹
        if messages[0].get("role") != "system":
            raise ValueError("First message must be system prompt")

        # 3. æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒuserã‹
        if messages[-1].get("role") != "user":
            raise ValueError("Last message must be user message")

        # 4. role/contentãŒå­˜åœ¨ã™ã‚‹ã‹
        for i, msg in enumerate(messages):
            if "role" not in msg or "content" not in msg:
                raise ValueError(f"Message {i} missing role or content")
            if not msg["content"]:
                raise ValueError(f"Message {i} has empty content")

        # 5. ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒä¸Šé™ã‚’è¶…ãˆã¦ã„ãªã„ã‹ï¼ˆè­¦å‘Šã®ã¿ï¼‰
        if total_tokens > self.config.max_tokens:
            import warnings

            warnings.warn(
                f"Total tokens {total_tokens} exceeds max {self.config.max_tokens}"
            )
```

**ãƒ†ã‚¹ãƒˆä½œæˆ**: å¾Œè¿°ï¼ˆDay 3ï¼‰

---

### Day 3: KanaAIBridgeçµ±åˆã¨ãƒ†ã‚¹ãƒˆ

#### Step 3.1: KanaAIBridgeæ‹¡å¼µ

`bridge/providers/ai/kana_ai_bridge.py` ã‚’ä¿®æ­£:

```python
"""Kana (Anthropic Claude) AI bridge implementation."""

from __future__ import annotations

import os
from typing import Any, Dict, Optional

from anthropic import APIStatusError, AsyncAnthropic

from bridge.core.ai_bridge import AIBridge


class KanaAIBridge(AIBridge):
    """Wrap Anthropic Claude as the Kana intent processor."""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "claude-3-5-sonnet-20241022",
        client: Optional[AsyncAnthropic] = None,
        # â†“ è¿½åŠ 
        context_assembler: Optional[Any] = None,  # ContextAssemblerService
    ) -> None:
        key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not key and client is None:
            raise ValueError("ANTHROPIC_API_KEY must be configured for KanaAIBridge")
        self._model = model
        self._client = client or AsyncAnthropic(api_key=key)
        self._context_assembler = context_assembler

    async def process_intent(self, intent: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process intent with context memory support

        Args:
            intent: Intent dict with fields:
                - content: str (user message) - required
                - user_id: str - optional, default "default"
                - session_id: UUID - optional

        Returns:
            Response dict with status, summary, and optional context_metadata
        """
        user_message = intent.get("content", "")
        user_id = intent.get("user_id", "default")
        session_id = intent.get("session_id")

        # Context AssemblerãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€æ–‡è„ˆã‚’æ§‹ç¯‰
        if self._context_assembler:
            try:
                assembled = await self._context_assembler.assemble_context(
                    user_message=user_message,
                    user_id=user_id,
                    session_id=session_id,
                )
                messages = assembled.messages
                context_metadata = assembled.metadata
            except Exception as e:
                # Contextçµ„ã¿ç«‹ã¦ã«å¤±æ•—ã—ãŸå ´åˆã¯fallback
                import warnings
                warnings.warn(f"Context assembly failed: {e}, falling back to simple mode")
                messages = self._build_simple_messages(user_message)
                context_metadata = None
        else:
            # Context Assembleræœªè¨­å®šã®å ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            messages = self._build_simple_messages(user_message)
            context_metadata = None

        # Claude APIå‘¼ã³å‡ºã—
        try:
            response = await self._client.messages.create(
                model=self._model,
                max_tokens=4096,
                temperature=0.5,
                messages=messages,
            )
        except APIStatusError as exc:  # pragma: no cover
            return {
                "status": "error",
                "reason": str(exc),
            }

        message = response.content[0]
        summary = getattr(message, "text", None) or str(message)

        result = {
            "status": "ok",
            "model": self._model,
            "summary": summary,
        }

        # Context metadataè¿½åŠ 
        if context_metadata:
            result["context_metadata"] = {
                "working_memory_count": context_metadata.working_memory_count,
                "semantic_memory_count": context_metadata.semantic_memory_count,
                "has_session_summary": context_metadata.has_session_summary,
                "total_tokens": context_metadata.total_tokens,
                "compression_applied": context_metadata.compression_applied,
            }

        return result

    def _build_simple_messages(self, user_message: str) -> list:
        """Fallback: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆï¼ˆå¾“æ¥ã®å‹•ä½œï¼‰"""
        return [
            {
                "role": "system",
                "content": "You are Kana, the external translator for Resonant Engine.",
            },
            {
                "role": "user",
                "content": user_message,
            },
        ]

    @staticmethod
    def _build_prompt(intent: Dict[str, Any]) -> str:
        """å¾“æ¥ã®promptæ§‹ç¯‰ï¼ˆäº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰"""
        intent_type = intent.get("type", "unknown")
        payload = intent.get("payload", {})
        return (
            "# Intent Summary\n"
            f"Type: {intent_type}\n"
            "Describe the key considerations, potential risks, and immediate next actions.\n\n"
            "## Payload\n"
            f"{payload}"
        )
```

#### Step 3.2: E2Eãƒ†ã‚¹ãƒˆä½œæˆ

`tests/context_assembler/test_e2e.py`:

```python
"""E2E Test for Context Assembler + KanaAIBridge Integration"""

import pytest
from uuid import uuid4

# ... (è©³ç´°ã¯å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆä»•æ§˜æ›¸ã«è¨˜è¼‰)


@pytest.mark.asyncio
async def test_full_context_flow_with_kana_bridge(
    context_assembler,
    message_repo,
    memory_store,
    kana_bridge,
):
    """
    å®Œå…¨ãªãƒ•ãƒ­ãƒ¼:
    1. éå»ã®ä¼šè©±ã‚’ä¿å­˜
    2. é•·æœŸè¨˜æ†¶ã‚’ä¿å­˜
    3. Context Assemblerã§çµ±åˆ
    4. KanaAIBridgeã§Claude APIå‘¼ã³å‡ºã—
    5. å¿œç­”ã«éå»ã®æ–‡è„ˆãŒåæ˜ ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    """
    # ãƒ†ã‚¹ãƒˆå®Ÿè£…...
    pass
```

---

### Day 4-5: ãƒ†ã‚¹ãƒˆå®Œæˆã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼

- çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿæ–½
- æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿæ–½
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
- ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾å¿œ

---

## âœ… å®Œäº†æ¡ä»¶

### å¿…é ˆæ¡ä»¶
- [ ] å…¨å˜ä½“ãƒ†ã‚¹ãƒˆãŒPASSï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸ > 80%ï¼‰
- [ ] å…¨çµ±åˆãƒ†ã‚¹ãƒˆãŒPASS
- [ ] E2Eãƒ†ã‚¹ãƒˆãŒPASSï¼ˆå®Ÿéš›ã®ä¼šè©±ãƒ•ãƒ­ãƒ¼ã§å‹•ä½œç¢ºèªï¼‰
- [ ] KanaAIBridgeçµ±åˆãŒå®Œäº†ã—ã€Context Assembleræœªè¨­å®šæ™‚ã‚‚fallbackã§å‹•ä½œ
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå®Œæˆï¼ˆREADME + APIä»•æ§˜ï¼‰

### å“è³ªæ¡ä»¶
- [ ] Contextçµ„ã¿ç«‹ã¦ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· < 100ms
- [ ] ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šç²¾åº¦ Â±10% ä»¥å†…
- [ ] ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆruff, mypyï¼‰ãŒPASS

### ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¡ä»¶
- [ ] å®å•“ã•ã‚“ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†
- [ ] Yunoã«ã‚ˆã‚‹è¨­è¨ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†
- [ ] å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆå®Ÿæ–½å®Œäº†

---

## ğŸ“š å‚è€ƒè³‡æ–™

- [Context Assemblerä»•æ§˜æ›¸](../architecture/sprint5_context_assembler_spec.md)
- [å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆä»•æ§˜æ›¸](../test/sprint5_acceptance_test_spec.md)
- [Claude API Documentation](https://docs.anthropic.com/claude/reference/messages)

---

**ä½œæˆæ—¥**: 2025-11-18
**ä½œæˆè€…**: Kana (Claude Sonnet 4.5)
