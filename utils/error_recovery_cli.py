#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Error Recovery CLI - ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã®ç®¡ç†ãƒ»å†å®Ÿè¡Œãƒ„ãƒ¼ãƒ«
=====================================================
ãƒ‡ãƒƒãƒ‰ãƒ¬ã‚¿ãƒ¼ã‚­ãƒ¥ãƒ¼ã‚„ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç¢ºèªãƒ»å†å®Ÿè¡Œã™ã‚‹CLI
"""

import sys
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.resilient_event_stream import ResilientEventStream, EventStatus, ErrorCategory
from utils.metrics_collector import get_metrics_collector

class ErrorRecoveryCLI:
    """ã‚¨ãƒ©ãƒ¼ãƒªã‚«ãƒãƒªãƒ¼ç”¨CLIãƒ„ãƒ¼ãƒ«"""
    
    def __init__(self):
        self.stream = ResilientEventStream()
        self.metrics = get_metrics_collector()
    
    def show_status(self):
        """ã‚¨ãƒ©ãƒ¼çŠ¶æ³ã®æ¦‚è¦ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print("ğŸ“Š Resonant Engine - Error Recovery Status")
        print("=" * 60)
        print()
        
        # çµ±è¨ˆæƒ…å ±
        failed = self.stream.get_failed_events()
        dlq = self.stream.get_dead_letter_queue()
        retry_candidates = self.stream.get_retry_candidates()
        
        print(f"âŒ Failed Events: {len(failed)}")
        print(f"ğŸ’€ Dead Letter Queue: {len(dlq)}")
        print(f"ğŸ”„ Retry Candidates: {len(retry_candidates)}")
        print()
        
        if not dlq and not failed:
            print("âœ… No errors detected - system is healthy!")
            return
        
        # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        error_by_category = {}
        for event in dlq + failed:
            error_info = event.get("error_info", {})
            category = error_info.get("category", "unknown")
            error_by_category[category] = error_by_category.get(category, 0) + 1
        
        print("Error Breakdown:")
        for category, count in error_by_category.items():
            emoji = "âš¡" if category == "transient" else "ğŸš«" if category == "permanent" else "â“"
            print(f"  {emoji} {category}: {count}")
        print()
    
    def list_dead_letter_queue(self, limit: int = 20):
        """ãƒ‡ãƒƒãƒ‰ãƒ¬ã‚¿ãƒ¼ã‚­ãƒ¥ãƒ¼ã‚’ä¸€è¦§è¡¨ç¤º"""
        print("=" * 60)
        print("ğŸ’€ Dead Letter Queue")
        print("=" * 60)
        print()
        
        dlq_events = self.stream.get_dead_letter_queue(limit=limit)
        
        if not dlq_events:
            print("âœ… Dead letter queue is empty!")
            return
        
        for i, event in enumerate(dlq_events, 1):
            self._print_event_summary(i, event, show_details=False)
    
    def list_failed_events(self, limit: int = 20):
        """å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä¸€è¦§è¡¨ç¤º"""
        print("=" * 60)
        print("âŒ Failed Events")
        print("=" * 60)
        print()
        
        failed = self.stream.get_failed_events(limit=limit)
        
        if not failed:
            print("âœ… No failed events!")
            return
        
        for i, event in enumerate(failed, 1):
            self._print_event_summary(i, event, show_details=False)
    
    def list_retry_candidates(self):
        """ãƒªãƒˆãƒ©ã‚¤å€™è£œã‚’ä¸€è¦§è¡¨ç¤º"""
        print("=" * 60)
        print("ğŸ”„ Retry Candidates (Transient Errors)")
        print("=" * 60)
        print()
        
        candidates = self.stream.get_retry_candidates()
        
        if not candidates:
            print("âœ… No retry candidates found!")
            return
        
        for i, event in enumerate(candidates, 1):
            self._print_event_summary(i, event, show_details=True)
    
    def show_event_detail(self, event_id: str):
        """ç‰¹å®šã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print(f"ğŸ” Event Detail: {event_id}")
        print("=" * 60)
        print()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œç´¢
        event = self._find_event(event_id)
        
        if not event:
            print(f"âŒ Event not found: {event_id}")
            return
        
        # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
        print(f"Event ID: {event['event_id']}")
        print(f"Timestamp: {event['timestamp']}")
        print(f"Type: {event['event_type']}")
        print(f"Source: {event['source']}")
        print(f"Status: {event['status']}")
        print()
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±
        if event.get("error_info"):
            print("Error Information:")
            error_info = event["error_info"]
            print(f"  Category: {error_info.get('category')}")
            print(f"  Type: {error_info.get('type')}")
            print(f"  Message: {error_info.get('message')}")
            print()
            
            if error_info.get("stacktrace"):
                print("Stack Trace:")
                print(error_info["stacktrace"])
                print()
        
        # ãƒªãƒˆãƒ©ã‚¤æƒ…å ±
        if event.get("retry_info"):
            print("Retry Information:")
            retry_info = event["retry_info"]
            print(f"  Count: {retry_info.get('count')}/{retry_info.get('max_retries')}")
            if retry_info.get("next_retry_at"):
                print(f"  Next Retry: {retry_info['next_retry_at']}")
            print()
        
        # ãƒªã‚«ãƒãƒªãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if event.get("recovery_actions"):
            print("Recovery Actions:")
            for action in event["recovery_actions"]:
                print(f"  - {action['timestamp']}: {action['action']}")
            print()
        
        # ãƒ‡ãƒ¼ã‚¿
        print("Event Data:")
        print(json.dumps(event.get("data", {}), indent=2, ensure_ascii=False))
        print()
    
    def export_errors_report(self, output_path: str = "error_report.json"):
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        report = {
            "generated_at": datetime.now().isoformat(),
            "summary": {
                "failed_events": len(self.stream.get_failed_events()),
                "dead_letter_queue": len(self.stream.get_dead_letter_queue()),
                "retry_candidates": len(self.stream.get_retry_candidates())
            },
            "dead_letter_queue": self.stream.get_dead_letter_queue(),
            "failed_events": self.stream.get_failed_events(),
            "retry_candidates": self.stream.get_retry_candidates()
        }
        
        output = Path(output_path)
        with open(output, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Error report exported to: {output.absolute()}")
    
    def retry_event(self, event_id: str):
        """æ‰‹å‹•ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒªãƒˆãƒ©ã‚¤"""
        print(f"ğŸ”„ Retrying event: {event_id}")
        print()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œç´¢
        event = self._find_event(event_id)
        
        if not event:
            print(f"âŒ Event not found: {event_id}")
            return
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèª
        error_info = event.get("error_info", {})
        error_category = error_info.get("category")
        
        if error_category == "permanent":
            print(f"âš ï¸  Warning: This event has a permanent error.")
            print(f"   Error: {error_info.get('message')}")
            print(f"   Retrying may not resolve the issue.")
            print()
            response = input("Continue anyway? (y/N): ")
            if response.lower() != 'y':
                print("âŒ Retry cancelled.")
                return
        
        # ãƒªãƒˆãƒ©ã‚¤å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        # æ³¨æ„: å®Ÿéš›ã®ãƒªãƒˆãƒ©ã‚¤ã«ã¯ã€å…ƒã®actionã®å†å®Ÿè¡ŒãŒå¿…è¦
        # ç¾åœ¨ã¯ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã«ãƒªãƒˆãƒ©ã‚¤è¨˜éŒ²ã‚’è¿½åŠ 
        print("ğŸ“ Recording retry attempt...")
        
        retry_event_data = {
            "original_event_id": event_id,
            "retry_type": "manual",
            "retry_timestamp": datetime.now().isoformat(),
            "original_error": error_info.get('message')
        }
        
        new_event_id = self.stream.emit(
            event_type="manual_retry",
            source="error_recovery_cli",
            data=retry_event_data,
            parent_event_id=event_id,
            tags=["manual_retry", "recovery"],
            importance=4,
            status=EventStatus.PENDING
        )
        
        print(f"âœ… Retry recorded: {new_event_id}")
        print()
        print("ğŸ’¡ Note: This is a manual retry record.")
        print("   To actually re-execute the action, you need to:")
        print("   1. Identify the original action from event data")
        print("   2. Re-execute it programmatically or manually")
        print()
    
    def show_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print("ğŸ“Š Metrics Summary")
        print("=" * 60)
        print()
        
        summary = self.metrics.get_summary()
        
        # åŸºæœ¬çµ±è¨ˆ
        print("ğŸ“ˆ Event Statistics:")
        print(f"  Total Events: {summary['total_events']}")
        print(f"  Success: {summary['success_events']} ({summary['success_rate']}%)")
        print(f"  Failed: {summary['failed_events']} ({summary['error_rate']}%)")
        print(f"  Dead Letter: {summary['dead_letter_events']}")
        print()
        
        # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒª
        if summary.get('error_categories'):
            print("âš¡ Error Categories:")
            for category, count in summary['error_categories'].items():
                print(f"  {category}: {count}")
            print()
        
        # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
        if summary.get('error_types'):
            print("ğŸš« Error Types:")
            for error_type, count in summary['error_types'].items():
                print(f"  {error_type}: {count}")
            print()
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼
        if summary.get('latency_stats'):
            latency = summary['latency_stats']
            print("â±ï¸ Latency (ms):")
            print(f"  Min: {latency.get('min', 0):.0f}")
            print(f"  Avg: {latency.get('avg', 0):.0f}")
            print(f"  P50: {latency.get('p50', 0):.0f}")
            print(f"  P95: {latency.get('p95', 0):.0f}")
            print(f"  P99: {latency.get('p99', 0):.0f}")
            print(f"  Max: {latency.get('max', 0):.0f}")
            print()
        
        # ãƒªãƒˆãƒ©ã‚¤
        if summary.get('retry_stats'):
            retry = summary['retry_stats']
            print("ğŸ”„ Retry Statistics:")
            print(f"  Total Retries: {retry.get('total_retries', 0)}")
            print(f"  Avg Retries: {retry.get('avg_retries', 0):.2f}")
            print(f"  Max Retries: {retry.get('max_retries', 0)}")
            print()
        
        print(f"âŒ› Last Updated: {summary.get('last_updated', 'N/A')}")
        print()
    
    def export_prometheus(self, output_path: str = "metrics.prom"):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’Prometheuså½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        prom_data = self.metrics.export_prometheus_format()
        
        output = Path(output_path)
        with open(output, "w", encoding="utf-8") as f:
            f.write(prom_data)
        
        print(f"âœ… Prometheus metrics exported to: {output.absolute()}")
        print()
    
    def purge_old_events(self, days: int):
        """å¤ã„DLQã‚¤ãƒ™ãƒ³ãƒˆã‚’å‰Šé™¤"""
        print(f"ğŸ—‘ï¸  Purging events older than {days} days...")
        print()
        
        if not self.stream.dead_letter_path.exists():
            print("âœ… Dead letter queue is empty.")
            return
        
        # ç¾åœ¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        from datetime import timedelta
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # DLQã‚’èª­ã¿è¾¼ã‚“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        kept_events = []
        purged_count = 0
        
        with open(self.stream.dead_letter_path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    event = json.loads(line)
                    event_time = datetime.fromisoformat(event["timestamp"])
                    
                    if event_time >= cutoff_date:
                        kept_events.append(event)
                    else:
                        purged_count += 1
                except (json.JSONDecodeError, ValueError, KeyError):
                    continue
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã
        with open(self.stream.dead_letter_path, "w", encoding="utf-8") as f:
            for event in kept_events:
                f.write(json.dumps(event, ensure_ascii=False) + "\n")
        
        print(f"âœ… Purged {purged_count} events.")
        print(f"   Kept {len(kept_events)} events.")
        print()
    
    def _print_event_summary(self, index: int, event: Dict[str, Any], show_details: bool = False):
        """ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        error_info = event.get("error_info", {})
        retry_info = event.get("retry_info", {})
        
        category_emoji = {
            "transient": "âš¡",
            "permanent": "ğŸš«",
            "unknown": "â“"
        }
        emoji = category_emoji.get(error_info.get("category"), "â“")
        
        print(f"{index}. [{emoji}] {event['event_id']}")
        print(f"   Timestamp: {event['timestamp']}")
        print(f"   Source: {event['source']} | Type: {event['event_type']}")
        print(f"   Error: {error_info.get('message', 'N/A')}")
        
        if retry_info:
            print(f"   Retries: {retry_info.get('count', 0)}/{retry_info.get('max_retries', 0)}")
        
        if show_details and error_info.get("category") == "transient":
            print(f"   ğŸ’¡ Suggestion: This error may be transient. Consider manual retry.")
        
        print()
    
    def _find_event(self, event_id: str) -> Optional[Dict[str, Any]]:
        """ã‚¤ãƒ™ãƒ³ãƒˆIDã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œç´¢"""
        # ã¾ãšãƒ¡ã‚¤ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’æ¤œç´¢
        if self.stream.stream_path.exists():
            with open(self.stream.stream_path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        event = json.loads(line)
                        if event["event_id"] == event_id:
                            return event
                    except json.JSONDecodeError:
                        continue
        
        # ãƒ‡ãƒƒãƒ‰ãƒ¬ã‚¿ãƒ¼ã‚­ãƒ¥ãƒ¼ã‚‚æ¤œç´¢
        if self.stream.dead_letter_path.exists():
            with open(self.stream.dead_letter_path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        event = json.loads(line)
                        if event["event_id"] == event_id:
                            return event
                    except json.JSONDecodeError:
                        continue
        
        return None


def main():
    """CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Error Recovery CLI - Manage failed events and dead letter queue"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Available commands")
    
    # status ã‚³ãƒãƒ³ãƒ‰
    subparsers.add_parser("status", help="Show error recovery status")
    
    # dlq ã‚³ãƒãƒ³ãƒ‰
    dlq_parser = subparsers.add_parser("dlq", help="List dead letter queue")
    dlq_parser.add_argument("--limit", type=int, default=20, help="Maximum events to show")
    
    # failed ã‚³ãƒãƒ³ãƒ‰
    failed_parser = subparsers.add_parser("failed", help="List failed events")
    failed_parser.add_argument("--limit", type=int, default=20, help="Maximum events to show")
    
    # retry-candidates ã‚³ãƒãƒ³ãƒ‰
    subparsers.add_parser("retry-candidates", help="List retry candidates")
    
    # detail ã‚³ãƒãƒ³ãƒ‰
    detail_parser = subparsers.add_parser("detail", help="Show event detail")
    detail_parser.add_argument("event_id", help="Event ID to inspect")
    
    # export ã‚³ãƒãƒ³ãƒ‰
    export_parser = subparsers.add_parser("export", help="Export error report")
    export_parser.add_argument("--output", default="error_report.json", help="Output file path")
    
    # retry ã‚³ãƒãƒ³ãƒ‰ (P1-3: æ–°è¦è¿½åŠ )
    retry_parser = subparsers.add_parser("retry", help="Manually retry an event from DLQ")
    retry_parser.add_argument("event_id", help="Event ID to retry")
    
    # purge ã‚³ãƒãƒ³ãƒ‰ (P1-3: æ–°è¦è¿½åŠ )
    purge_parser = subparsers.add_parser("purge", help="Purge old DLQ events")
    purge_parser.add_argument("--older-than", type=int, default=30, help="Delete events older than N days (default: 30)")
    
    # metrics ã‚³ãƒãƒ³ãƒ‰ (P1-4: æ–°è¦è¿½åŠ )
    subparsers.add_parser("metrics", help="Show metrics summary")
    
    # prometheus ã‚³ãƒãƒ³ãƒ‰ (P1-4: æ–°è¦è¿½åŠ )
    prom_parser = subparsers.add_parser("prometheus", help="Export Prometheus metrics")
    prom_parser.add_argument("--output", default="metrics.prom", help="Output file path")
    
    args = parser.parse_args()
    
    cli = ErrorRecoveryCLI()
    
    if args.command == "status":
        cli.show_status()
    elif args.command == "dlq":
        cli.list_dead_letter_queue(limit=args.limit)
    elif args.command == "failed":
        cli.list_failed_events(limit=args.limit)
    elif args.command == "retry-candidates":
        cli.list_retry_candidates()
    elif args.command == "detail":
        cli.show_event_detail(args.event_id)
    elif args.command == "export":
        cli.export_errors_report(output_path=args.output)
    elif args.command == "retry":  # P1-3: æ–°è¦è¿½åŠ 
        cli.retry_event(args.event_id)
    elif args.command == "purge":  # P1-3: æ–°è¦è¿½åŠ 
        cli.purge_old_events(days=args.older_than)
    elif args.command == "metrics":  # P1-4: æ–°è¦è¿½åŠ 
        cli.show_metrics()
    elif args.command == "prometheus":  # P1-4: æ–°è¦è¿½åŠ 
        cli.export_prometheus(output_path=args.output)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
