#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Metrics Collector - P1-4: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†åŸºç›¤
=====================================================
ã‚¨ãƒ©ãƒ¼ã€ãƒªãƒˆãƒ©ã‚¤ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
from collections import defaultdict
from threading import Lock


class MetricsCollector:
    """
    è»½é‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ 
    
    åé›†é …ç›®:
    - ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆIDåˆ¥ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰
    - ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ã€ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
    - ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼çµ±è¨ˆ
    - ãƒ‡ãƒƒãƒ‰ãƒ¬ã‚¿ãƒ¼ã‚­ãƒ¥ãƒ¼å¢—åŠ ç‡
    """
    
    def __init__(self, metrics_path: Path = None):
        """
        Args:
            metrics_path: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        base_dir = Path(__file__).parent.parent / "logs"
        self.metrics_path = metrics_path or base_dir / "metrics.json"
        self.metrics_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.lock = Lock()
        self.metrics = self._load_metrics()
    
    def _load_metrics(self) -> Dict[str, Any]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if self.metrics_path.exists():
            try:
                with open(self.metrics_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError):
                pass
        
        return {
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "counters": {
                "total_events": 0,
                "success_events": 0,
                "failed_events": 0,
                "retried_events": 0,
                "dead_letter_events": 0
            },
            "error_categories": defaultdict(int),
            "error_types": defaultdict(int),
            "retry_counts": [],  # ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°
            "latencies": [],  # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ï¼ˆmsï¼‰
            "hourly_stats": {}  # æ™‚é–“åˆ¥çµ±è¨ˆ
        }
    
    def _save_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜"""
        with self.lock:
            self.metrics["last_updated"] = datetime.now().isoformat()
            
            # defaultdictã‚’dictã«å¤‰æ›
            if isinstance(self.metrics.get("error_categories"), defaultdict):
                self.metrics["error_categories"] = dict(self.metrics["error_categories"])
            if isinstance(self.metrics.get("error_types"), defaultdict):
                self.metrics["error_types"] = dict(self.metrics["error_types"])
            
            with open(self.metrics_path, "w", encoding="utf-8") as f:
                json.dump(self.metrics, f, indent=2, ensure_ascii=False)
    
    def record_event(self, status: str, error_category: Optional[str] = None, 
                     error_type: Optional[str] = None, retry_count: int = 0,
                     latency_ms: Optional[int] = None):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
        
        Args:
            status: ã‚¤ãƒ™ãƒ³ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ (success/failed/retrying/dead_letter)
            error_category: ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒª (transient/permanent/unknown)
            error_type: ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ— (ValueError, ConnectionErrorç­‰)
            retry_count: ãƒªãƒˆãƒ©ã‚¤å›æ•°
            latency_ms: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ï¼ˆãƒŸãƒªç§’ï¼‰
        """
        with self.lock:
            counters = self.metrics["counters"]
            counters["total_events"] += 1
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            if status == "success":
                counters["success_events"] += 1
            elif status == "failed":
                counters["failed_events"] += 1
            elif status == "retrying":
                counters["retried_events"] += 1
            elif status == "dead_letter":
                counters["dead_letter_events"] += 1
            
            # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒª
            if error_category:
                if isinstance(self.metrics["error_categories"], dict):
                    self.metrics["error_categories"] = defaultdict(int, self.metrics["error_categories"])
                self.metrics["error_categories"][error_category] += 1
            
            # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
            if error_type:
                if isinstance(self.metrics["error_types"], dict):
                    self.metrics["error_types"] = defaultdict(int, self.metrics["error_types"])
                self.metrics["error_types"][error_type] += 1
            
            # ãƒªãƒˆãƒ©ã‚¤å›æ•°
            if retry_count > 0:
                self.metrics["retry_counts"].append(retry_count)
            
            # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼
            if latency_ms is not None:
                self.metrics["latencies"].append(latency_ms)
                # ãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼šæœ€æ–°1000ä»¶ã®ã¿ä¿æŒ
                if len(self.metrics["latencies"]) > 1000:
                    self.metrics["latencies"] = self.metrics["latencies"][-1000:]
            
            # æ™‚é–“åˆ¥çµ±è¨ˆ
            hour_key = datetime.now().strftime("%Y-%m-%d %H:00")
            if hour_key not in self.metrics["hourly_stats"]:
                self.metrics["hourly_stats"][hour_key] = {
                    "total": 0,
                    "success": 0,
                    "failed": 0,
                    "retried": 0
                }
            
            self.metrics["hourly_stats"][hour_key]["total"] += 1
            if status == "success":
                self.metrics["hourly_stats"][hour_key]["success"] += 1
            elif status in ["failed", "dead_letter"]:
                self.metrics["hourly_stats"][hour_key]["failed"] += 1
            elif status == "retrying":
                self.metrics["hourly_stats"][hour_key]["retried"] += 1
        
        self._save_metrics()
    
    def get_summary(self) -> Dict[str, Any]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        with self.lock:
            counters = self.metrics["counters"]
            total = counters["total_events"]
            
            if total == 0:
                return {
                    "total_events": 0,
                    "success_rate": 0.0,
                    "error_rate": 0.0,
                    "retry_rate": 0.0
                }
            
            # æˆåŠŸç‡ãƒ»ã‚¨ãƒ©ãƒ¼ç‡
            success_rate = counters["success_events"] / total * 100
            error_rate = counters["failed_events"] / total * 100
            retry_rate = counters["retried_events"] / total * 100
            
            # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼çµ±è¨ˆ
            latencies = self.metrics.get("latencies", [])
            latency_stats = {}
            if latencies:
                latencies_sorted = sorted(latencies)
                latency_stats = {
                    "min": min(latencies),
                    "max": max(latencies),
                    "avg": sum(latencies) / len(latencies),
                    "p50": latencies_sorted[len(latencies) // 2],
                    "p95": latencies_sorted[int(len(latencies) * 0.95)],
                    "p99": latencies_sorted[int(len(latencies) * 0.99)]
                }
            
            # ãƒªãƒˆãƒ©ã‚¤çµ±è¨ˆ
            retry_counts = self.metrics.get("retry_counts", [])
            retry_stats = {}
            if retry_counts:
                retry_stats = {
                    "avg_retries": sum(retry_counts) / len(retry_counts),
                    "max_retries": max(retry_counts),
                    "total_retries": sum(retry_counts)
                }
            
            return {
                "total_events": total,
                "success_events": counters["success_events"],
                "failed_events": counters["failed_events"],
                "dead_letter_events": counters["dead_letter_events"],
                "success_rate": round(success_rate, 2),
                "error_rate": round(error_rate, 2),
                "retry_rate": round(retry_rate, 2),
                "error_categories": dict(self.metrics.get("error_categories", {})),
                "error_types": dict(self.metrics.get("error_types", {})),
                "latency_stats": latency_stats,
                "retry_stats": retry_stats,
                "last_updated": self.metrics.get("last_updated")
            }
    
    def export_prometheus_format(self) -> str:
        """
        Prometheuså½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Returns:
            Prometheus ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        summary = self.get_summary()
        lines = []
        
        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        lines.append("# HELP resonant_events_total Total number of events")
        lines.append("# TYPE resonant_events_total counter")
        lines.append(f"resonant_events_total {summary['total_events']}")
        lines.append("")
        
        lines.append("# HELP resonant_events_success Success events")
        lines.append("# TYPE resonant_events_success counter")
        lines.append(f"resonant_events_success {summary['success_events']}")
        lines.append("")
        
        lines.append("# HELP resonant_events_failed Failed events")
        lines.append("# TYPE resonant_events_failed counter")
        lines.append(f"resonant_events_failed {summary['failed_events']}")
        lines.append("")
        
        lines.append("# HELP resonant_events_dead_letter Dead letter queue events")
        lines.append("# TYPE resonant_events_dead_letter counter")
        lines.append(f"resonant_events_dead_letter {summary['dead_letter_events']}")
        lines.append("")
        
        # ã‚²ãƒ¼ã‚¸ï¼ˆç‡ï¼‰
        lines.append("# HELP resonant_success_rate Success rate percentage")
        lines.append("# TYPE resonant_success_rate gauge")
        lines.append(f"resonant_success_rate {summary['success_rate']}")
        lines.append("")
        
        lines.append("# HELP resonant_error_rate Error rate percentage")
        lines.append("# TYPE resonant_error_rate gauge")
        lines.append(f"resonant_error_rate {summary['error_rate']}")
        lines.append("")
        
        # ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªåˆ¥
        if summary.get("error_categories"):
            lines.append("# HELP resonant_errors_by_category Errors by category")
            lines.append("# TYPE resonant_errors_by_category counter")
            for category, count in summary["error_categories"].items():
                lines.append(f'resonant_errors_by_category{{category="{category}"}} {count}')
            lines.append("")
        
        # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼
        if summary.get("latency_stats"):
            latency = summary["latency_stats"]
            lines.append("# HELP resonant_latency_ms Latency in milliseconds")
            lines.append("# TYPE resonant_latency_ms summary")
            lines.append(f"resonant_latency_ms_avg {latency.get('avg', 0)}")
            lines.append(f"resonant_latency_ms_p50 {latency.get('p50', 0)}")
            lines.append(f"resonant_latency_ms_p95 {latency.get('p95', 0)}")
            lines.append(f"resonant_latency_ms_p99 {latency.get('p99', 0)}")
            lines.append("")
        
        return "\n".join(lines)
    
    def reset_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        with self.lock:
            self.metrics = {
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "counters": {
                    "total_events": 0,
                    "success_events": 0,
                    "failed_events": 0,
                    "retried_events": 0,
                    "dead_letter_events": 0
                },
                "error_categories": defaultdict(int),
                "error_types": defaultdict(int),
                "retry_counts": [],
                "latencies": [],
                "hourly_stats": {}
            }
            self._save_metrics()


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_metrics_collector = None

def get_metrics_collector() -> MetricsCollector:
    """ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®MetricsCollectorã‚’å–å¾—"""
    global _metrics_collector
    if _metrics_collector is None:
        _metrics_collector = MetricsCollector()
    return _metrics_collector


if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    collector = MetricsCollector()
    
    print("=== Metrics Collector Demo ===\n")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
    collector.record_event("success", latency_ms=120)
    collector.record_event("success", latency_ms=95)
    collector.record_event("failed", error_category="transient", error_type="ConnectionError", retry_count=2, latency_ms=1500)
    collector.record_event("retrying", error_category="transient", error_type="TimeoutError", retry_count=1, latency_ms=3000)
    collector.record_event("dead_letter", error_category="transient", error_type="TimeoutError", retry_count=3, latency_ms=5000)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = collector.get_summary()
    print("ğŸ“Š Metrics Summary:")
    print(json.dumps(summary, indent=2, ensure_ascii=False))
    print()
    
    # Prometheuså½¢å¼
    print("ğŸ“ˆ Prometheus Format:")
    print(collector.export_prometheus_format())
